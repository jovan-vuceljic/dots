# see https://github.com/sigoden/aichat/blob/main/config.example.yaml

model: llamacpp:default
clients:
- type: openai-compatible
  name: ollama
  api_base: http://127.0.0.1:11434/v1
  models:
  - name: deepcoder:14b
  - name: gemma3:12b
  - name: gemma3n:latest
  - name: gpt-oss:latest
  - name: qwen3:14b
- type: openai-compatible
  name: llamacpp
  api_base: http://127.0.0.1:11343/v1
  models:
  - name: default
  - name: qwen3-coder:30b
  - name: qwen3:14b
